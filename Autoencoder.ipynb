{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os        \n",
    "from random import shuffle \n",
    "from tqdm import tqdm \n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains 3000 Non Varying Image\n",
    "\n",
    "# TRAIN_DIR = '/home/sauradip/Desktop/cnn-tf/data/raw-data/mix'\n",
    "# TEST_DIR = '/home/sauradip/Desktop/cnn-tf/data/raw-data/mix'\n",
    "\n",
    "# Contains 5000+ Variation IMages\n",
    "\n",
    "TRAIN_DIR = '/home/sauradip/Desktop/cnn-tf/data/new data/resized'\n",
    "TEST_DIR = '/home/sauradip/Desktop/cnn-tf/data/new data/resized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100 # Resizing and reshaping \n",
    "LR = 1e-3 # Learning Rate is 0.001\n",
    "MODEL_NAME = 'gesture-{}-{}.model'.format(LR, '8_new_data_conv-basic') # just so we remember which saved model is which, sizes must match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img[0]\n",
    "    # conversion to one-hot array [index,v-shape,fist,terminal]\n",
    "   \n",
    "    if word_label == 'i': return [1,0,0,0]                            \n",
    "    elif word_label == 'v': return [0,1,0,0]\n",
    "    elif word_label == 'f': return [0,0,1,0]\n",
    "    elif word_label == 't': return [0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = create_train_data()\n",
    "# If i have already created the dataset ,i will just load it :\n",
    "train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "encoder = tflearn.input_data(shape=[None, IMG_SIZE*IMG_SIZE])\n",
    "encoder = tflearn.fully_connected(encoder, 256)\n",
    "encoder = tflearn.fully_connected(encoder, 64)\n",
    "\n",
    "# Building the decoder\n",
    "decoder = tflearn.fully_connected(encoder, 256)\n",
    "decoder = tflearn.fully_connected(decoder, IMG_SIZE*IMG_SIZE, activation='sigmoid')\n",
    "\n",
    "# Regression, with mean square error\n",
    "net = tflearn.regression(decoder, optimizer='adam', learning_rate=LR,\n",
    "                         loss='mean_square', metric=None)\n",
    "\n",
    "# Training the auto encoder\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0 , tensorboard_dir='log')\n",
    "train=[]\n",
    "test=[]\n",
    "train = train_data[:-4000]\n",
    "test = train_data[-1000:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i1[1] for i1 in train]\n",
    "\n",
    "test_x = np.array([i2[0] for i2 in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i3[1] for i3 in test]\n",
    "model.fit(X, Y, n_epoch=20, validation_set=(test_x, test_y),\n",
    "          run_id=\"auto_encoder\", batch_size=256)\n",
    "model.save(\"/home/sauradip/Desktop/cnn-tf/model/\"+MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i need to create the data:\n",
    "#test_data = process_test_data()\n",
    "# if i already have some saved:\n",
    "test_data = np.load('test_data.npy')\n",
    "show=20 # number of images to be shown\n",
    "col=4 # no of columns to be displayed\n",
    "fig=plt.figure()\n",
    "labelss = []\n",
    "predics = []\n",
    "for num,data in enumerate(test_data[:show]):\n",
    "    #[index,v-shape,fist,terminal]\n",
    "    \n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    if img_num == \"i\":\n",
    "        labelss.append(1)\n",
    "    elif img_num == \"v\":\n",
    "        labelss.append(2)\n",
    "    elif img_num == \"f\":\n",
    "        labelss.append(3)\n",
    "    elif img_num == \"t\":\n",
    "        labelss.append(4)\n",
    "    \n",
    "    y = fig.add_subplot((show/col),col,num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    #model_out = model.predict([data])[0]\n",
    "    model_out = (model.predict([data])[0]).round()\n",
    "    if np.array_equal((model_out),np.array([1.,0.,0.,0.])):\n",
    "        str_label='index'\n",
    "        predics.append(1)\n",
    "    elif np.array_equal((model_out),np.array([0.,1.,0.,0.]) ): \n",
    "        str_label='vshape'\n",
    "        predics.append(2)\n",
    "    elif np.array_equal((model_out) , np.array([0.,0.,1.,0.])): \n",
    "        str_label='fist'\n",
    "        predics.append(3)\n",
    "    elif np.array_equal((model_out) , np.array([0.,0.,0.,1.])): \n",
    "        str_label='thumb'\n",
    "        predics.append(4)\n",
    "    \n",
    "        \n",
    "    y.imshow(orig,cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labelss, predics))\n",
    "\n",
    "#print('Precision of the Model is '+str(precision*100) + ' %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
